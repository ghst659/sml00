{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0867a2f6-af61-46f5-a14e-8522c9eb8aa2",
   "metadata": {},
   "source": [
    "# NLP With TensorFlow/Keras\n",
    "\n",
    "Reference: https://medium.com/geekculture/nlp-with-tensorflow-keras-explanation-and-tutorial-cae3554b1290"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a674f5a-2801-4c01-b063-deb8ea3345b7",
   "metadata": {},
   "source": [
    "## Main Concepts\n",
    "\n",
    "### Tokenization\n",
    "* Splits sentence into tokens (often words)\n",
    "* Remove unimportant chars like punctuation\n",
    "\n",
    "### Stop Word Removal\n",
    "* Remove irrelevant words: \"and\", \"to\", \"the\" --- may depend on the purpose of the model\n",
    "* Increases model accuracy during training\\\n",
    "\n",
    "### Stemming\n",
    "* \"waiting\" and \"waited\" become \"wait\"\n",
    "\n",
    "### Lemmatization\n",
    "* normalise to base form: \"went\" -> \"go\"\n",
    "* \"joyful\" -> \"good\"\n",
    "\n",
    "## Topic Modelling\n",
    "* Unsupervised learning\n",
    "* Groups texts under certain subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee7c74-3530-42bf-9eaf-3ee3b054f2c3",
   "metadata": {},
   "source": [
    "## Tutorial: Detect Text Emotion\n",
    "\n",
    "Dataset: English Twitter messages https://huggingface.co/datasets/emotion\n",
    "* `nlp` module can be used to import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c662b5-0884-4a6a-ac3c-3c8a8e5d6f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 02:28:32.262213: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import nlp  # https://pypi.org/project/nlp/\n",
    "import datasets\n",
    "import random\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b14bc7-7243-4d83-8bd4-2c78dc00648a",
   "metadata": {},
   "source": [
    "### Import and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416d266d-b5e3-4c5d-b68b-b7d88becdcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset loading using nlp failed because file train.txt had been deletd from dropbox.\n",
    "# Belowis from https://huggingface.co/datasets/dair-ai/emotion?library=datasets\n",
    "# split_ds = datasets.load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "# unsplit_ds = datasets.load_dataset(\"dair-ai/emotion\", \"unsplit\")\n",
    "\n",
    "# Updated to use https://huggingface.co/datasets/dair-ai/emotion\n",
    "DATASET = \"dair-ai/emotion\"\n",
    "LABEL_MAP = {\n",
    "    0: \"sadness\",\n",
    "    1: \"joy\",\n",
    "    2: \"love\",\n",
    "    3: \"anger\",\n",
    "    4: \"fear\",\n",
    "    5: \"surprise\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f0afcdd-b18e-4c09-82ea-f47d8d9a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = split_ds[\"train\"]\n",
    "# val = split_ds[\"validation\"]\n",
    "# test = split_ds[\"test\"]\n",
    "# From https://huggingface.co/docs/hub/datasets-usage\n",
    "train_dataset = datasets.load_dataset(DATASET, split=\"train\")\n",
    "valid_dataset = datasets.load_dataset(DATASET, split=\"validation\")\n",
    "test_dataset = datasets.load_dataset(DATASET, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfaf2f3b-3fca-48b6-a576-4791d45d22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(data: datasets.arrow_dataset.Dataset) -> tuple[list[str], list[str]]:\n",
    "    \"\"\"Splits a data split into its tweets and labels.\"\"\"\n",
    "    tweets = [x[\"text\"] for x in data]\n",
    "    labels = [LABEL_MAP[x[\"label\"]] for x in data]\n",
    "    return tweets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ff0ed7-d54d-4b2b-9596-bcaffbaac917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i didnt feel humiliated sadness\n"
     ]
    }
   ],
   "source": [
    "tweets, labels = get_tweet(train_dataset)\n",
    "print(tweets[0], labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15678ae-0f00-4437-b9c7-ddc04fdacb81",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Assign each word a number by how commonly the appear in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd81f6d-699c-4348-90b3-19d7a55d93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the deprecated https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(tweets)  # Calibrate to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b9531-7010-4b25-80fb-9d3ad69d92ee",
   "metadata": {},
   "source": [
    "### Make all Sequences Same Shape\n",
    "\n",
    "The ML model expects inputs to be a fixed shape and length.\n",
    "\n",
    "Turn all tweets to the same length of `MAXLEN`, adding empty spaces and cutting off extra words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "029546d2-9893-4cc3-89e0-5938dc800002",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAXLEN = 50\n",
    "def get_sequences(tokenizer: tf.keras.preprocessing.text.Tokenizer, tweets: list[str]) -> list[str]:\n",
    "    sequences = tokenizer.texts_to_sequences(tweets)\n",
    "    padded = tf.keras.utils.pad_sequences(sequences, truncating = \"post\", padding=\"post\", maxlen=MAXLEN)\n",
    "    return padded\n",
    "\n",
    "# Because the Tokenizer is now deprecated, prepare a vectorizer layer for the model.\n",
    "vec_layer = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAXLEN,\n",
    ")\n",
    "vec_layer.adapt(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edbe7ee4-fc40-408d-9474-20a6e75e5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train_seq = get_sequences(tokenizer, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0eea32e-4b09-4e8d-8cd8-df51a8d9a5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i didnt feel humiliated 50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  2, 139,   3, 679,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweets[0], len(padded_train_seq[0]))\n",
    "padded_train_seq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41598faa-86f2-42a1-9a7b-d38fe37f189c",
   "metadata": {},
   "source": [
    "### Preparing Data for Model\n",
    "\n",
    "Create a set for all the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b73e0e3-199e-4bd9-969b-59a13e98d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_class = LABEL_MAP.copy()\n",
    "classes = set(index_to_class.values())\n",
    "class_to_index = {\n",
    "    c: i\n",
    "    for i, c in index_to_class.items()\n",
    "}\n",
    "def names_to_ids(labels: list[str]) -> np.ndarray:\n",
    "    return np.array([class_to_index[x] for x in labels])\n",
    "train_labels = names_to_ids(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "012e84b1-7e69-4b32-8c85-c2d6ebb6f357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sadness': 0, 'joy': 1, 'love': 2, 'anger': 3, 'fear': 4, 'surprise': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24748521-4376-45b3-b721-b7ff0cbe0b5f",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "* 1 embedding layer.  https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "* 2 bidirectional LSTM layers --- allow 2-way communication.  https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* 1 dense layer for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80eb6ce4-1683-4d44-9a1f-11778218903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_layers = [\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 16, input_length=MAXLEN),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "]\n",
    "\n",
    "old_model = tf.keras.models.Sequential(common_layers)\n",
    "\n",
    "vec_model = tf.keras.models.Sequential([vec_layer, *common_layers])\n",
    "    \n",
    "model = old_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0fc5c-582c-430a-98b2-f5a480a71ee3",
   "metadata": {},
   "source": [
    "#### Model Compilation:\n",
    "* use the Adam optimiser https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "* loss function sparse categorical cross-entropy https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15d1ac9c-51ee-4b7b-902e-1fc4074ef88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "     loss=\"sparse_categorical_crossentropy\",\n",
    "     optimizer=\"adam\",\n",
    "     metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514f0a6-9778-4428-a9eb-94e064b0e5d5",
   "metadata": {},
   "source": [
    "### Training\n",
    "* use callbacks to halt the training when validation accuracy does not increase for more than 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07716c84-6e10-435a-b0ff-320ba5bdbed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 45ms/step - accuracy: 0.3816 - loss: 1.5293 - val_accuracy: 0.6605 - val_loss: 1.0141\n",
      "Epoch 2/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.7384 - loss: 0.6994 - val_accuracy: 0.8045 - val_loss: 0.5934\n",
      "Epoch 3/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.8707 - loss: 0.3726 - val_accuracy: 0.8400 - val_loss: 0.4751\n",
      "Epoch 4/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 44ms/step - accuracy: 0.9160 - loss: 0.2554 - val_accuracy: 0.8670 - val_loss: 0.4214\n",
      "Epoch 5/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - accuracy: 0.9427 - loss: 0.1756 - val_accuracy: 0.8670 - val_loss: 0.4131\n",
      "Epoch 6/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 42ms/step - accuracy: 0.9584 - loss: 0.1429 - val_accuracy: 0.8855 - val_loss: 0.3949\n",
      "Epoch 7/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 45ms/step - accuracy: 0.9642 - loss: 0.1184 - val_accuracy: 0.8895 - val_loss: 0.3686\n",
      "Epoch 8/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 46ms/step - accuracy: 0.9726 - loss: 0.0903 - val_accuracy: 0.8830 - val_loss: 0.4156\n",
      "Epoch 9/20\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - accuracy: 0.9724 - loss: 0.0882 - val_accuracy: 0.8805 - val_loss: 0.4218\n"
     ]
    }
   ],
   "source": [
    "val_tweets, val_labels = get_tweet(valid_dataset)\n",
    "val_seq = get_sequences(tokenizer, val_tweets)\n",
    "val_labels= names_to_ids(val_labels)\n",
    "h = model.fit(\n",
    "     padded_train_seq, train_labels,\n",
    "     validation_data=(val_seq, val_labels),\n",
    "     epochs=20,\n",
    "     callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39da3fd-0c7c-4b04-a493-44b173b024da",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2ba74aa-c299-446f-bd98-aeb8c737cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets, test_labels=get_tweet(test_dataset)\n",
    "test_seq = get_sequences(tokenizer, test_tweets)\n",
    "test_labels=names_to_ids(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894dc7c0-0d1f-4c7a-b9a9-bb55847e34b6",
   "metadata": {},
   "source": [
    "Evaluate model accuracy against test data.\n",
    "* `metrics_value` will correspond to the `metrics=\"accuracy\"` given during model compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47172267-6a00-4dbf-85e8-f141f0120020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8839 - loss: 0.3977\n"
     ]
    }
   ],
   "source": [
    "loss_value, metrics_value = model.evaluate(test_seq, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be2e2a5b-7354-4012-9d6a-fa269f001a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4076148271560669, 0.8794999718666077)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_value, metrics_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73828a-c6fc-4168-99ec-3b041c3ff2fd",
   "metadata": {},
   "source": [
    "#### Random model sampling\n",
    "Generate a random tweet, and predicdt its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "043c9fa8-8aa7-4274-9f95-acfe6b6dec41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: i found myself feeling inhibited and shushing her quite a lot\n",
      "Emotion: sadness\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815ms/step\n",
      "[   2  323   51    8 1067    4    1   68  157    7  159    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0]\n",
      "Predicted Emotion:  sadness\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0,len(test_labels)-1)\n",
    "print('Sentence:', test_tweets[i])\n",
    "print('Emotion:', index_to_class[test_labels[i]])\n",
    "p = model.predict(np.expand_dims(test_seq[i], axis=0))[0]\n",
    "print(test_seq[i])\n",
    "pred_class=index_to_class[np.argmax(p).astype('uint8')]\n",
    "print('Predicted Emotion: ', pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b3a03a-3856-4f63-ac39-7fb4dabdfa68",
   "metadata": {},
   "source": [
    "#### Classifying an Input Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63129ef8-9b20-442b-aa0b-aa76f1186b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Sentence: goodbye frustration\n",
      "Predicted Emotion:  anger\n"
     ]
    }
   ],
   "source": [
    "sentence = 'goodbye frustration'\n",
    "sequence = tokenizer.texts_to_sequences([sentence])\n",
    "paddedSequence = tf.keras.utils.pad_sequences(sequence, truncating = 'post', padding='post', maxlen=MAXLEN)\n",
    "p = model.predict(np.expand_dims(paddedSequence[0], axis=0))[0]\n",
    "pred_class=index_to_class[np.argmax(p).astype('uint8')]\n",
    "print('Sentence:', sentence)\n",
    "print('Predicted Emotion: ', pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7a177-a709-429b-b0c2-d8ff93ea37d3",
   "metadata": {},
   "source": [
    "### Saving the Model\n",
    "Save in Hierarchical Data Format 5 (`h5`) format. \n",
    "See https://medium.com/@mysterious_obscure/a-deep-dive-into-model-files-pkl-pt-h5-and-the-magic-of-machine-learning-740768317e76\n",
    "\n",
    "Formats:\n",
    "* `.pkl` = Pickled Python Objects - used by `scikit-learn`\n",
    "* `.p5` = Pytorch Tensors - stores architecture and learned params as tensors\n",
    "* `.h5` = Hierarchical Data Format 5 stores architecture, learned params and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9306a310-9c16-4dbc-a634-5aecb9131e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally for Google Collab and Drive.\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "# path = \"/content/drive/My Drive/TweetEmotionRecognition/h5/tweet_model.h5\"\n",
    "# path = \"/tmp/tweet_model.h5\"\n",
    "# model.save(path)\n",
    "# Save in more modern keras format.\n",
    "path = \"/tmp/tweet_model.keras\"\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe67bc65-4986-412f-be6d-e790c15423b4",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "698dda60-ec83-48d8-b763-45fa59f7ac7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,920</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,760</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m16\u001b[0m)           │       \u001b[38;5;34m160,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m40\u001b[0m)           │         \u001b[38;5;34m5,920\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m40\u001b[0m)               │         \u001b[38;5;34m9,760\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m6\u001b[0m)                │           \u001b[38;5;34m246\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">527,780</span> (2.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m527,780\u001b[0m (2.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">175,926</span> (687.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m175,926\u001b[0m (687.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">351,854</span> (1.34 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m351,854\u001b[0m (1.34 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "load_model = tf.keras.models.load_model(path)\n",
    "print(load_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d03ba-7e33-4e63-8899-2e2be7f503e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
