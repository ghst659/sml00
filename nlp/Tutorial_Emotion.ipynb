{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0867a2f6-af61-46f5-a14e-8522c9eb8aa2",
   "metadata": {},
   "source": [
    "# NLP With TensorFlow/Keras\n",
    "\n",
    "Reference: https://medium.com/geekculture/nlp-with-tensorflow-keras-explanation-and-tutorial-cae3554b1290"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a674f5a-2801-4c01-b063-deb8ea3345b7",
   "metadata": {},
   "source": [
    "## Main Concepts\n",
    "\n",
    "### Tokenization\n",
    "* Splits sentence into tokens (often words)\n",
    "* Remove unimportant chars like punctuation\n",
    "\n",
    "### Stop Word Removal\n",
    "* Remove irrelevant words: \"and\", \"to\", \"the\" --- may depend on the purpose of the model\n",
    "* Increases model accuracy during training\\\n",
    "\n",
    "### Stemming\n",
    "* \"waiting\" and \"waited\" become \"wait\"\n",
    "\n",
    "### Lemmatization\n",
    "* normalise to base form: \"went\" -> \"go\"\n",
    "* \"joyful\" -> \"good\"\n",
    "\n",
    "## Topic Modelling\n",
    "* Unsupervised learning\n",
    "* Groups texts under certain subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee7c74-3530-42bf-9eaf-3ee3b054f2c3",
   "metadata": {},
   "source": [
    "## Tutorial: Detect Text Emotion\n",
    "\n",
    "Dataset: English Twitter messages https://huggingface.co/datasets/emotion\n",
    "* `nlp` module can be used to import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c662b5-0884-4a6a-ac3c-3c8a8e5d6f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp  # https://pypi.org/project/nlp/\n",
    "import datasets\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b14bc7-7243-4d83-8bd4-2c78dc00648a",
   "metadata": {},
   "source": [
    "### Import and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d266d-b5e3-4c5d-b68b-b7d88becdcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset loading using nlp failed because file train.txt had been deletd from dropbox.\n",
    "# Belowis from https://huggingface.co/datasets/dair-ai/emotion?library=datasets\n",
    "split_ds = datasets.load_dataset(\"dair-ai/emotion\", \"split\")\n",
    "unsplit_ds = datasets.load_dataset(\"dair-ai/emotion\", \"unsplit\")\n",
    "LABEL_MAP = {\n",
    "    0: \"sadness\",\n",
    "    1: \"joy\",\n",
    "    2: \"love\",\n",
    "    3: \"anger\",\n",
    "    4: \"fear\",\n",
    "    5: \"surprise\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0afcdd-b18e-4c09-82ea-f47d8d9a3fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = split_ds[\"train\"]\n",
    "val = split_ds[\"validation\"]\n",
    "test = split_ds[\"test\"]\n",
    "# From https://huggingface.co/docs/hub/datasets-usage\n",
    "train_dataset = datasets.load_dataset(\"dair-ai/emotion\", split=\"train\")\n",
    "valid_dataset = datasets.load_dataset(\"dair-ai/emotion\", split=\"validation\")\n",
    "test_dataset = datasets.load_dataset(\"dair-ai/emotion\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf2f3b-3fca-48b6-a576-4791d45d22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweet(data: datasets.arrow_dataset.Dataset) -> tuple[list[str], list[str]]:\n",
    "    \"\"\"Splits a data split into its tweets and labels.\"\"\"\n",
    "    tweets = [x[\"text\"] for x in data]\n",
    "    labels = [LABEL_MAP[x[\"label\"]] for x in data]\n",
    "    return tweets, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ff0ed7-d54d-4b2b-9596-bcaffbaac917",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, labels = get_tweet(train_dataset)\n",
    "print(tweets[0], labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15678ae-0f00-4437-b9c7-ddc04fdacb81",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Assign each word a number by how commonly the appear in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd81f6d-699c-4348-90b3-19d7a55d93cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(tweets)  # Calibrate to the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b9531-7010-4b25-80fb-9d3ad69d92ee",
   "metadata": {},
   "source": [
    "### Make all Sequences Same Shape\n",
    "\n",
    "The ML model expects inputs to be a fixed shape and length.\n",
    "\n",
    "Turn all tweets to the same length of 50, adding empty spaces and cutting off extra words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029546d2-9893-4cc3-89e0-5938dc800002",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 50\n",
    "def get_sequences(tokenizer: Tokenizer, tweets: list[str]) -> list[str]:\n",
    "    sequences = tokenizer.texts_to_sequences(tweets)\n",
    "    padded = pad_sequences(sequences, truncating = 'post', padding='post', maxlen=MAXLEN)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbe7ee4-fc40-408d-9474-20a6e75e5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train_seq = get_sequences(tokenizer, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eea32e-4b09-4e8d-8cd8-df51a8d9a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train_seq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41598faa-86f2-42a1-9a7b-d38fe37f189c",
   "metadata": {},
   "source": [
    "### Preparing Data for Model\n",
    "\n",
    "Create a set for all the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73e0e3-199e-4bd9-969b-59a13e98d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_class = LABEL_MAP.copy()\n",
    "classes = set(index_to_class.values())\n",
    "class_to_index = dict((c, i) for i, c in index_to_class.items())\n",
    "names_to_ids = lambda labels: np.array([class_to_index.get(x) for x in labels])\n",
    "train_labels = names_to_ids(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e84b1-7e69-4b32-8c85-c2d6ebb6f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24748521-4376-45b3-b721-b7ff0cbe0b5f",
   "metadata": {},
   "source": [
    "### Model Definition\n",
    "\n",
    "* 1 embedding layer.  https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "* 2 bidirectional LSTM layers --- allow 2-way communication.  https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "* 1 dense layer for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eb6ce4-1683-4d44-9a1f-11778218903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(10000,16, input_length=MAXLEN),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "    tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0fc5c-582c-430a-98b2-f5a480a71ee3",
   "metadata": {},
   "source": [
    "#### Model Compilation:\n",
    "* use the Adam optimiser https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n",
    "* loss function sparse categorical cross-entropy https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d1ac9c-51ee-4b7b-902e-1fc4074ef88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "     loss=\"sparse_categorical_crossentropy\",\n",
    "     optimizer=\"adam\",\n",
    "     metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9514f0a6-9778-4428-a9eb-94e064b0e5d5",
   "metadata": {},
   "source": [
    "### Training\n",
    "* use callbacks to halt the training when validation accuracy does not increase for more than 2 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07716c84-6e10-435a-b0ff-320ba5bdbed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_tweets, val_labels = get_tweet(valid_dataset)\n",
    "val_seq = get_sequences(tokenizer, val_tweets)\n",
    "val_labels= names_to_ids(val_labels)\n",
    "h = model.fit(\n",
    "     padded_train_seq, train_labels,\n",
    "     validation_data=(val_seq, val_labels),\n",
    "     epochs=20,\n",
    "     callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39da3fd-0c7c-4b04-a493-44b173b024da",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ba74aa-c299-446f-bd98-aeb8c737cb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweets, test_labels=get_tweet(test_dataset)\n",
    "test_seq = get_sequences(tokenizer, test_tweets)\n",
    "test_labels=names_to_ids(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894dc7c0-0d1f-4c7a-b9a9-bb55847e34b6",
   "metadata": {},
   "source": [
    "Evaluate model accuracy against test data.\n",
    "* `metrics_value` will correspond to the `metrics=\"accuracy\"` given during model compilation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47172267-6a00-4dbf-85e8-f141f0120020",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value, metrics_value = model.evaluate(test_seq, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e2a5b-7354-4012-9d6a-fa269f001a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value, metrics_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73828a-c6fc-4168-99ec-3b041c3ff2fd",
   "metadata": {},
   "source": [
    "#### Random model sampling\n",
    "Generate a random tweet, and predicdt its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c9fa8-8aa7-4274-9f95-acfe6b6dec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0,len(test_labels)-1)\n",
    "print('Sentence:', test_tweets[i])\n",
    "print('Emotion:', index_to_class[test_labels[i]])\n",
    "p = model.predict(np.expand_dims(test_seq[i], axis=0))[0]\n",
    "print(test_seq[i])\n",
    "pred_class=index_to_class[np.argmax(p).astype('uint8')]\n",
    "print('Predicted Emotion: ', pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b3a03a-3856-4f63-ac39-7fb4dabdfa68",
   "metadata": {},
   "source": [
    "#### Classifying an Input Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63129ef8-9b20-442b-aa0b-aa76f1186b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'i am not sure what to do'\n",
    "sequence = tokenizer.texts_to_sequences([sentence])\n",
    "paddedSequence = pad_sequences(sequence, truncating = 'post', padding='post', maxlen=MAXLEN)\n",
    "p = model.predict(np.expand_dims(paddedSequence[0], axis=0))[0]\n",
    "pred_class=index_to_class[np.argmax(p).astype('uint8')]\n",
    "print('Sentence:', sentence)\n",
    "print('Predicted Emotion: ', pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7a177-a709-429b-b0c2-d8ff93ea37d3",
   "metadata": {},
   "source": [
    "### Saving the Model\n",
    "Save in Hierarchical Data Format 5 (`h5`) format. \n",
    "See https://medium.com/@mysterious_obscure/a-deep-dive-into-model-files-pkl-pt-h5-and-the-magic-of-machine-learning-740768317e76\n",
    "\n",
    "Formats:\n",
    "* `.pkl` = Pickled Python Objects - used by `scikit-learn`\n",
    "* `.p5` = Pytorch Tensors - stores architecture and learned params as tensors\n",
    "* `.h5` = Hierarchical Data Format 5 stores architecture, learned params and training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9306a310-9c16-4dbc-a634-5aecb9131e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally for Google Collab and Drive.\n",
    "# from google.colab import drive\n",
    "# drive.mount(\"/content/drive\")\n",
    "# path = \"/content/drive/My Drive/TweetEmotionRecognition/h5/tweet_model.h5\"\n",
    "path = \"/tmp/tweet_model.h5\"\n",
    "model.save(path)\n",
    "# Save in more modern keras format.\n",
    "path = \"/tmp/tweet_model.keras\"\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe67bc65-4986-412f-be6d-e790c15423b4",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698dda60-ec83-48d8-b763-45fa59f7ac7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "load_model = tf.keras.models.load_model(path)\n",
    "print(load_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d03ba-7e33-4e63-8899-2e2be7f503e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
